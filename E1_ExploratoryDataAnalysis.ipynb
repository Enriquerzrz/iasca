{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# E1: Exploratory data analysis\n",
        "### Enrique Ruiz Ruiz"
      ],
      "metadata": {
        "id": "pEFI7RaGYgd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Assignment goal\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "The goal of this assignment is to perform an exploratory data analysis of a simple dataset. To this end, create a notebook, load a dataset of your interest and apply techniques developed in along the lecture (summary statistics and/or graphical tools).\n",
        "\n",
        "Remember that the goal of an exploratory analysis is not to provide a definitive answer to a question, but rather to get an insight to the data to better frame futher analysis. In other words, we want to describe our data instead of reaching solid conclusions.\n",
        "\n",
        "You may want to consider the following structure to guide your EDA.\n",
        "\n",
        "*   First contact\n",
        "  *   Visualize your raw data.\n",
        "  *   Count number of instances and attributes (rows and columns).\n",
        "  *   Identify your variables.\n",
        "  *   Find out if there are duplicates and NaNs and handle them.\n",
        "  *   Get summary statistics (max, min, avg) and identify whether there are outlayers.\n",
        "*   Visualize your variables distribution (univariable).\n",
        "*   Identify correlations among your variables (bivariable)."
      ],
      "metadata": {
        "id": "z-Ae6NFnY35m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Resolution\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mJPpfsHdanrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JeavCm9kcLW3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using seaborn we can gather relevant data from the ***planets*** dataset.\n"
      ],
      "metadata": {
        "id": "pXSVS85icMLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wvPPKziyX4Ip"
      },
      "outputs": [],
      "source": [
        "# Load the dataset of exoplantes\n",
        "df_planets = sns.load_dataset('planets');\n",
        "\n",
        "# 1035 rows × 6 columns\n",
        "# [method - number - orbital_period - mass - distance - year]\n",
        "\n",
        "#Get some info of the varibles\n",
        "method_types = df_planets['method'].unique();\n",
        "\n",
        "# Decomment the next line to previsualice the data set\n",
        "# df_planets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count number of instances and attributes (rows and columns).\n",
        "*   1035 rows × 6 columns\n",
        "\n",
        "Identify the variables.\n",
        "*    method (string)\n",
        "    *   'Radial Velocity'\n",
        "    *   'Imaging'\n",
        "    *   'Eclipse Timing Variations'\n",
        "    *   'Transit'\n",
        "    *   'Astrometry'\n",
        "    *   'Transit Timing Variations'\n",
        "    *   'Orbital Brightness Modulation'\n",
        "    *   'Microlensing'\n",
        "    *   'Pulsar Timing'\n",
        "    *   'Pulsation Timing Variations\n",
        "*    number (int)\n",
        "*    orbital_period (float)\n",
        "*    mass (float)\n",
        "*    distance (float)\n",
        "*    year (date)\n",
        "\n",
        "We have to clean and preprocess data following steps like:\n",
        "  * Handle missing values (remove, fill, or interpolate).\n",
        "  * Remove duplicates and irrelevant features."
      ],
      "metadata": {
        "id": "F99b7qlxcEBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove NaN data\n",
        "df_planets = df_planets.dropna()\n",
        "\n",
        "# 2. Remove duplicates\n",
        "df_planets = df_planets.drop_duplicates()\n",
        "\n",
        "# After clean the data we have\n",
        "# 498 rows × 6 columns\n",
        "# [method - number - orbital_period - mass - distance - year]\n",
        "\n",
        "# Decomment the next line to previsualice the data set\n",
        "# df_planets"
      ],
      "metadata": {
        "id": "RtHAq0e2cFjY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a lot of duplicates now, the data set has 498 rows instead of 1035."
      ],
      "metadata": {
        "id": "dVySfgDghAKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get summary statistics (max, min, avg) and identify whether there are outlayers.\n"
      ],
      "metadata": {
        "id": "G_XM7pybhLfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}